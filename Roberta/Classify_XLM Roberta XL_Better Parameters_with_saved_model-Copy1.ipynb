{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b6d45-39c2-4d73-9bf4-905867efde31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers datasets pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8bdae80-cf40-482f-9002-0ddfb1ecb8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAR CACHE \n",
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a37acd1-8726-4dd8-97de-071910377300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type xlm-roberta-xl to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at facebook/xlm-roberta-xl and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.24.attention.output.LayerNorm.bias', 'roberta.encoder.layer.24.attention.output.LayerNorm.weight', 'roberta.encoder.layer.24.output.LayerNorm.bias', 'roberta.encoder.layer.24.output.LayerNorm.weight', 'roberta.encoder.layer.25.attention.output.LayerNorm.bias', 'roberta.encoder.layer.25.attention.output.LayerNorm.weight', 'roberta.encoder.layer.25.output.LayerNorm.bias', 'roberta.encoder.layer.25.output.LayerNorm.weight', 'roberta.encoder.layer.26.attention.output.LayerNorm.bias', 'roberta.encoder.layer.26.attention.output.LayerNorm.weight', 'roberta.encoder.layer.26.output.LayerNorm.bias', 'roberta.encoder.layer.26.output.LayerNorm.weight', 'roberta.encoder.layer.27.attention.output.LayerNorm.bias', 'roberta.encoder.layer.27.attention.output.LayerNorm.weight', 'roberta.encoder.layer.27.output.LayerNorm.bias', 'roberta.encoder.layer.27.output.LayerNorm.weight', 'roberta.encoder.layer.28.attention.output.LayerNorm.bias', 'roberta.encoder.layer.28.attention.output.LayerNorm.weight', 'roberta.encoder.layer.28.output.LayerNorm.bias', 'roberta.encoder.layer.28.output.LayerNorm.weight', 'roberta.encoder.layer.29.attention.output.LayerNorm.bias', 'roberta.encoder.layer.29.attention.output.LayerNorm.weight', 'roberta.encoder.layer.29.output.LayerNorm.bias', 'roberta.encoder.layer.29.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.30.attention.output.LayerNorm.bias', 'roberta.encoder.layer.30.attention.output.LayerNorm.weight', 'roberta.encoder.layer.30.output.LayerNorm.bias', 'roberta.encoder.layer.30.output.LayerNorm.weight', 'roberta.encoder.layer.31.attention.output.LayerNorm.bias', 'roberta.encoder.layer.31.attention.output.LayerNorm.weight', 'roberta.encoder.layer.31.output.LayerNorm.bias', 'roberta.encoder.layer.31.output.LayerNorm.weight', 'roberta.encoder.layer.32.attention.output.LayerNorm.bias', 'roberta.encoder.layer.32.attention.output.LayerNorm.weight', 'roberta.encoder.layer.32.output.LayerNorm.bias', 'roberta.encoder.layer.32.output.LayerNorm.weight', 'roberta.encoder.layer.33.attention.output.LayerNorm.bias', 'roberta.encoder.layer.33.attention.output.LayerNorm.weight', 'roberta.encoder.layer.33.output.LayerNorm.bias', 'roberta.encoder.layer.33.output.LayerNorm.weight', 'roberta.encoder.layer.34.attention.output.LayerNorm.bias', 'roberta.encoder.layer.34.attention.output.LayerNorm.weight', 'roberta.encoder.layer.34.output.LayerNorm.bias', 'roberta.encoder.layer.34.output.LayerNorm.weight', 'roberta.encoder.layer.35.attention.output.LayerNorm.bias', 'roberta.encoder.layer.35.attention.output.LayerNorm.weight', 'roberta.encoder.layer.35.output.LayerNorm.bias', 'roberta.encoder.layer.35.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, set_seed\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "set_all_seeds(42)\n",
    "\n",
    "start_time = time.time()\n",
    "# Load the dataset\n",
    "file_path = 'cleaned_history_text.csv'  # Update with the correct file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('facebook/xlm-roberta-xl')\n",
    "\n",
    "# Tokenize the text with truncation to max length\n",
    "max_length = 512\n",
    "texts = df['Text'].tolist()\n",
    "labels = df['Violence'].tolist()\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained('facebook/xlm-roberta-xl', num_labels=2)\n",
    "\n",
    "# Move to device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Function to classify sentences in batches\n",
    "def classify_sentences_in_batches(sentences, model, tokenizer, batch_size=4, max_length=512):\n",
    "    model.eval()\n",
    "    pred_labels = []\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "        encodings = tokenizer(batch, truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
    "        encodings = {key: val.to(device) for key, val in encodings.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encodings)\n",
    "            logits = outputs.logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        batch_pred_labels = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "        pred_labels.extend(batch_pred_labels)\n",
    "        # Clear CUDA cache to free memory\n",
    "        torch.cuda.empty_cache()\n",
    "    return np.array(pred_labels)\n",
    "\n",
    "# Evaluate the pre-trained model on the entire dataset\n",
    "pred_labels = classify_sentences_in_batches(texts, model, tokenizer, max_length=max_length)\n",
    "\n",
    "# Calculate overall metrics\n",
    "precision = precision_score(labels, pred_labels)\n",
    "recall = recall_score(labels, pred_labels)\n",
    "f1 = f1_score(labels, pred_labels)\n",
    "accuracy = accuracy_score(labels, pred_labels)\n",
    "\n",
    "print(f'Overall Precision: {precision:.4f}')\n",
    "print(f'Overall Recall: {recall:.4f}')\n",
    "print(f'Overall F1 Score: {f1:.4f}')\n",
    "print(f'Overall Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Generate classification report for both classes\n",
    "report = classification_report(labels, pred_labels, target_names=['Non-Violent', 'Violent'])\n",
    "print(report)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "hours, rem = divmod(elapsed_time, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(f\"Elapsed time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds\")\n",
    "\n",
    "# Print misclassified test sentences with their predicted and actual labels\n",
    "print(\"\\nMisclassified Test Sentences:\")\n",
    "print(\"-\" * 50)\n",
    "for sentence, actual_label, predicted_label in zip(texts, labels, pred_labels):\n",
    "    if actual_label != predicted_label:\n",
    "        print(f\"Sentence: \\n{sentence}\\nActual Label: {'Violent' if actual_label == 1 else 'Non-Violent'} | Predicted Label: {'Violent' if predicted_label == 1 else 'Non-Violent'}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(labels, pred_labels):\n",
    "    cm = confusion_matrix(labels, pred_labels)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Violent', 'Violent'], yticklabels=['Non-Violent', 'Violent'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "def plot_roc_curve(labels, predictions):\n",
    "    fpr, tpr, _ = roc_curve(labels, predictions[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(labels, pred_labels)\n",
    "\n",
    "# Plot the ROC curve\n",
    "logits = model(**tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(device)).logits\n",
    "probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "plot_roc_curve(labels, probs)\n",
    "\n",
    "# Example usage for new sentence classification\n",
    "new_sentences = [\n",
    "    \"This is a peaceful example.\",\n",
    "    \"He killed and beheaded all enemies.\"\n",
    "]\n",
    "new_pred_labels = classify_sentences_in_batches(new_sentences, model, tokenizer, max_length=max_length)\n",
    "\n",
    "# Print predictions with better formatting\n",
    "print(\"Predictions for New Sentences:\")\n",
    "print(\"-\" * 50)\n",
    "for sentence, label in zip(new_sentences, new_pred_labels):\n",
    "    print(f\"Sentence: \\n{sentence}\\nPredicted Label: {'Violent' if label == 1 else 'Non-Violent'}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a9c53f-2a1a-4edf-928e-744df2f06c3d",
   "metadata": {},
   "source": [
    "## Save Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42393d-0341-43f0-8db5-2b68ca86163d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9a29c7a-1445-4fec-ae4e-5e3ce44dc099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_model_Roberta_small_more_optimized/tokenizer_config.json',\n",
       " './saved_model_Roberta_small_more_optimized/special_tokens_map.json',\n",
       " './saved_model_Roberta_small_more_optimized/vocab.json',\n",
       " './saved_model_Roberta_small_more_optimized/merges.txt',\n",
       " './saved_model_Roberta_small_more_optimized/added_tokens.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained model and tokenizer\n",
    "model.save_pretrained('./saved_model_Roberta_small_more_optimized')\n",
    "tokenizer.save_pretrained('./saved_model_Roberta_small_more_optimized')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fa8b65-487f-4fad-b763-5e0fa81c73a1",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e472324-b8e1-4263-a2a1-a85e6a80019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "# Load the saved model and tokenizer\n",
    "model_path = './saved_model_bert'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1253987-42a9-482d-a27b-c92ddf8c64ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be116cbd-4b16-483b-bba6-76205b7ec181",
   "metadata": {},
   "source": [
    "## Predict New input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c74838b-a5bf-4229-aaed-102852c4f0f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for New Sentences:\n",
      "--------------------------------------------------\n",
      "Sentence: \n",
      "The most effective way to destroy people is to deny and obliterate their own understanding of their history.\n",
      "Predicted Label: Violent\n",
      "--------------------------------------------------\n",
      "Sentence: \n",
      "History is always written by the winners. When two cultures clash, the loser is obliterated, and the winner writes the history books. Books, which glorify their own cause and disparage the conquered foe. As Napoleon once said, what is history, but a fable agreed upon? \n",
      "Predicted Label: Non-Violent\n",
      "--------------------------------------------------\n",
      "Sentence: \n",
      "If you know the enemy and know yourself, you need not fear the result of a hundred battles. If you know yourself but not the enemy, for every victory gained you will also suffer a defeat. If you know neither the enemy nor yourself, you will succumb in every battle.\n",
      "Predicted Label: Non-Violent\n",
      "--------------------------------------------------\n",
      "Sentence: \n",
      "We shall defend our island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender.\n",
      "Predicted Label: Violent\n",
      "--------------------------------------------------\n",
      "Sentence: \n",
      "What has violence ever accomplished? What has it ever created? No martyr's cause has ever been stilled by an assassin's bullet. No wrongs have ever been righted by riots and civil disorders. A sniper is only a coward, not a hero; and an uncontrolled or uncontrollable mob is only the voice of madness, not the voice of the people.\n",
      "Predicted Label: Non-Violent\n",
      "--------------------------------------------------\n",
      "Sentence: \n",
      "Kill them all! slaughter them and behead them? leave none alive until they all surrender and give us all their money, power and women! I want to drink their blood and feast on their flesh! Leave none alive you hear me!\n",
      "Predicted Label: Violent\n",
      "--------------------------------------------------\n",
      "Sentence: \n",
      "While the Romans were in such difficulties, the barbarians suddenly surrounded them on all sides at once, coming through the densest thickets, as they were acquainted with the paths. At first they hurled their volleys from a distance; then, as no one defended himself and many were wounded, they approached closer to them. For the Romans were not proceeding in any regular order, but were mixed in helter-skelter with the waggons and the unarmed, and so, being unable to form readily anywhere in a body, and being fewer at every point than their assailants, they suffered greatly and could offer no resistance at all.\n",
      "Predicted Label: Violent\n",
      "--------------------------------------------------\n",
      "Sentence: \n",
      "In the battle, the knight broke the lines and slaughtered his enemies and then beheaded the king.\n",
      "Predicted Label: Violent\n",
      "--------------------------------------------------\n",
      "Sentence: \n",
      "I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character.\n",
      "Predicted Label: Non-Violent\n",
      "--------------------------------------------------\n",
      "Sentence: \n",
      "You can fool all of the people some of the time, and some of the people all of the time, but you can't fool all of the people all of the time.\n",
      "Predicted Label: Non-Violent\n",
      "--------------------------------------------------\n",
      "Sentence: \n",
      "Battles are won by slaughter and maneuver. The greater the general, the more he contributes in maneuver, the less he demands in slaughter.\n",
      "Predicted Label: Violent\n",
      "--------------------------------------------------\n",
      "Sentence: \n",
      "Remembering the loss of those Irishmen from all parts of the island who were sent to their deaths in the imperialist slaughter of the First World War is crucial to understanding our history. It is also important to recognise the special significance in which the Battle of the Somme and the First World War is held.\n",
      "Predicted Label: Violent\n",
      "--------------------------------------------------\n",
      "Sentence: \n",
      "In the battle, the soldiers started counting the sheeps that they got as a reward for their awersome performance. They managed to cheer the crowds and \n",
      "Predicted Label: Non-Violent\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Define a function to classify new sentences\n",
    "def classify_new_sentences(sentences, model, tokenizer):\n",
    "    # Tokenize the new sentences\n",
    "    encodings = tokenizer(sentences, truncation=True, padding=True, return_tensors='pt')\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    encodings = {key: val.to(device) for key, val in encodings.items()}\n",
    "    \n",
    "    # Make predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Convert logits to probabilities and then to labels\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "    pred_labels = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "    \n",
    "    return pred_labels\n",
    "\n",
    "# Example usage\n",
    "new_sentences = [\n",
    "   \n",
    "    # George Orwell\n",
    "    \"The most effective way to destroy people is to deny and obliterate their own understanding of their history.\",\n",
    "    # Dan Brown\n",
    "    \"History is always written by the winners. When two cultures clash, the loser is obliterated, and the winner writes the history books. Books, which glorify their own cause and disparage the conquered foe. As Napoleon once said, what is history, but a fable agreed upon? \",\n",
    "    # Sun Tzu\n",
    "    \"If you know the enemy and know yourself, you need not fear the result of a hundred battles. If you know yourself but not the enemy, for every victory gained you will also suffer a defeat. If you know neither the enemy nor yourself, you will succumb in every battle.\",\n",
    "    # Winston Churchill\n",
    "    \"We shall defend our island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender.\",\n",
    "    # Robert Kennedy\n",
    "    \"What has violence ever accomplished? What has it ever created? No martyr's cause has ever been stilled by an assassin's bullet. No wrongs have ever been righted by riots and civil disorders. A sniper is only a coward, not a hero; and an uncontrolled or uncontrollable mob is only the voice of madness, not the voice of the people.\",\n",
    "    \n",
    "    \"Kill them all! slaughter them and behead them? leave none alive until they all surrender and give us all their money, power and women! I want to drink their blood and feast on their flesh! Leave none alive you hear me!\",\n",
    "    \"While the Romans were in such difficulties, the barbarians suddenly surrounded them on all sides at once, coming through the densest thickets, as they were acquainted with the paths. At first they hurled their volleys from a distance; then, as no one defended himself and many were wounded, they approached closer to them. For the Romans were not proceeding in any regular order, but were mixed in helter-skelter with the waggons and the unarmed, and so, being unable to form readily anywhere in a body, and being fewer at every point than their assailants, they suffered greatly and could offer no resistance at all.\",\n",
    "    \"In the battle, the knight broke the lines and slaughtered his enemies and then beheaded the king.\",\n",
    "    \"I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character.\",\n",
    "    \"You can fool all of the people some of the time, and some of the people all of the time, but you can't fool all of the people all of the time.\",\n",
    "    \"Battles are won by slaughter and maneuver. The greater the general, the more he contributes in maneuver, the less he demands in slaughter.\",\n",
    "    \"Remembering the loss of those Irishmen from all parts of the island who were sent to their deaths in the imperialist slaughter of the First World War is crucial to understanding our history. It is also important to recognise the special significance in which the Battle of the Somme and the First World War is held.\",\n",
    "    \"In the battle, the soldiers started counting the sheeps that they got as a reward for their awersome performance. They managed to cheer the crowds and \"\n",
    "    \n",
    "]\n",
    "pred_labels = classify_new_sentences(new_sentences, model, tokenizer)\n",
    "\n",
    "\n",
    "# Print predictions with better formatting\n",
    "print(\"Predictions for New Sentences:\")\n",
    "print(\"-\" * 50)\n",
    "for sentence, label in zip(new_sentences, pred_labels):\n",
    "    print(f\"Sentence: \\n{sentence}\\nPredicted Label: {'Violent' if label == 1 else 'Non-Violent'}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2616f2-61bb-41a1-8e39-25c2a625ab33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40e9394f-cf4c-41aa-aee9-8ec7abba9756",
   "metadata": {},
   "source": [
    "## Parameter Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccd2cee1-258a-4e1d-988a-bb3eb3127eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109483778\n"
     ]
    }
   ],
   "source": [
    "print(f'{sum(p.numel() for p in model.parameters())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b935c63-9e30-46de-96ba-66bf593c3574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9038f2c-5e73-4d54-ae83-c47617fd27e5",
   "metadata": {},
   "source": [
    "## Trying without Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b8f38c-b748-4701-8d44-f5ea3d03f578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification, set_seed\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "set_all_seeds(42)\n",
    "\n",
    "start_time = time.time()\n",
    "# Load the dataset\n",
    "file_path = 'cleaned_history_text.csv'  # Update with the correct file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-large-discriminator')\n",
    "\n",
    "# Tokenize the text with truncation to max length\n",
    "max_length = 512\n",
    "texts = df['Text'].tolist()\n",
    "labels = df['Violence'].tolist()\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = ElectraForSequenceClassification.from_pretrained('google/electra-large-discriminator', num_labels=2)\n",
    "\n",
    "# Move to device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Function to classify sentences in batches\n",
    "def classify_sentences_in_batches(sentences, model, tokenizer, batch_size=100, max_length=512):  # Smaller batch size\n",
    "    model.eval()\n",
    "    pred_labels = []\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "        encodings = tokenizer(batch, truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
    "        encodings = {key: val.to(device) for key, val in encodings.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encodings)\n",
    "            logits = outputs.logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        batch_pred_labels = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "        pred_labels.extend(batch_pred_labels)\n",
    "        # Clear CUDA cache to free memory\n",
    "        torch.cuda.empty_cache()\n",
    "    return np.array(pred_labels)\n",
    "\n",
    "# Evaluate the pre-trained model on the entire dataset\n",
    "pred_labels = classify_sentences_in_batches(texts, model, tokenizer, max_length=max_length)\n",
    "\n",
    "# Calculate overall metrics\n",
    "precision = precision_score(labels, pred_labels)\n",
    "recall = recall_score(labels, pred_labels)\n",
    "f1 = f1_score(labels, pred_labels)\n",
    "accuracy = accuracy_score(labels, pred_labels)\n",
    "\n",
    "print(f'Overall Precision: {precision:.4f}')\n",
    "print(f'Overall Recall: {recall:.4f}')\n",
    "print(f'Overall F1 Score: {f1:.4f}')\n",
    "print(f'Overall Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Generate classification report for both classes\n",
    "report = classification_report(labels, pred_labels, target_names=['Non-Violent', 'Violent'])\n",
    "print(report)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "hours, rem = divmod(elapsed_time, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(f\"Elapsed time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds\")\n",
    "\n",
    "# Print misclassified test sentences with their predicted and actual labels\n",
    "print(\"\\nMisclassified Test Sentences:\")\n",
    "print(\"-\" * 50)\n",
    "for sentence, actual_label, predicted_label in zip(texts, labels, pred_labels):\n",
    "    if actual_label != predicted_label:\n",
    "        print(f\"Sentence: \\n{sentence}\\nActual Label: {'Violent' if actual_label == 1 else 'Non-Violent'} | Predicted Label: {'Violent' if predicted_label == 1 else 'Non-Violent'}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(labels, pred_labels):\n",
    "    cm = confusion_matrix(labels, pred_labels)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Violent', 'Violent'], yticklabels=['Non-Violent', 'Violent'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "def plot_roc_curve(labels, predictions):\n",
    "    fpr, tpr, _ = roc_curve(labels, predictions[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(labels, pred_labels)\n",
    "\n",
    "\n",
    "# Example usage for new sentence classification\n",
    "new_sentences = [\n",
    "    \"This is a peaceful example.\",\n",
    "    \"He killed and beheaded all enemies.\"\n",
    "]\n",
    "new_pred_labels = classify_sentences_in_batches(new_sentences, model, tokenizer, max_length=max_length)\n",
    "\n",
    "# Print predictions with better formatting\n",
    "print(\"Predictions for New Sentences:\")\n",
    "print(\"-\" * 50)\n",
    "for sentence, label in zip(new_sentences, new_pred_labels):\n",
    "    print(f\"Sentence: \\n{sentence}\\nPredicted Label: {'Violent' if label == 1 else 'Non-Violent'}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c627ec-844b-48a7-8d33-fe76f254ecdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dc4d99-fe30-4496-86a1-ec82ff34c897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96246637-a1db-4ed0-be66-31eae62fdcba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecee3d3-5a0e-45fb-9369-bc01bd68dd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71acec33-33f7-4588-892d-f67a0a155559",
   "metadata": {},
   "source": [
    "## TEST LATER FOR BETTER HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c37504f-e6f9-40cf-91e7-713f9a1f2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, load_metric\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'history_text.csv'  # Update with the correct file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df['Text'], df['Violence'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the text\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)\n",
    "\n",
    "# Convert to Dataset object\n",
    "train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'], 'attention_mask': train_encodings['attention_mask'], 'label': list(train_labels)})\n",
    "test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'], 'attention_mask': test_encodings['attention_mask'], 'label': list(test_labels)})\n",
    "\n",
    "# Define the model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=5,              # number of training epochs\n",
    "    per_device_train_batch_size=8,   # batch size for training\n",
    "    per_device_eval_batch_size=8,    # batch size for evaluation\n",
    "    learning_rate=2e-5,              # Adjust learning rate\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    eval_steps=10,\n",
    "    load_best_model_at_end=True,     # Load the best model at the end\n",
    "    metric_for_best_model=\"f1\",      # Define the metric to use for early stopping\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "# Define a function to compute metrics\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    precision = precision_score(labels, pred)\n",
    "    recall = recall_score(labels, pred)\n",
    "    f1 = f1_score(labels, pred)\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "# Define Trainer with early stopping callback\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # Early stopping\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to label IDs\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Calculate and print metrics\n",
    "precision = precision_score(test_labels, pred_labels)\n",
    "recall = recall_score(test_labels, pred_labels)\n",
    "f1 = f1_score(test_labels, pred_labels)\n",
    "accuracy = accuracy_score(test_labels, pred_labels)\n",
    "\n",
    "print(f'Overall Precision: {precision:.4f}')\n",
    "print(f'Overall Recall: {recall:.4f}')\n",
    "print(f'Overall F1 Score: {f1:.4f}')\n",
    "print(f'Overall Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Generate classification report for both classes\n",
    "report = classification_report(test_labels, pred_labels, target_names=['Non-Violent', 'Violent'])\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598c1985-bcdc-4d60-a434-50de4231a5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
